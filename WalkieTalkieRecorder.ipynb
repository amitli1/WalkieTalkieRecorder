{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "07ffc89c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container {width:100% !important;} </style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container {width:100% !important;} </style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a631621a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime\n",
    "import sys\n",
    "import glob\n",
    "import random\n",
    "import pickle\n",
    "\n",
    "import numpy         as np\n",
    "import pandas        as pd\n",
    "\n",
    "from scipy.fftpack   import fft\n",
    "from pydub           import AudioSegment\n",
    "from IPython.display import Audio\n",
    "\n",
    "from pydub.silence   import split_on_silence\n",
    "from pydub.silence   import detect_leading_silence\n",
    "\n",
    "from tqdm            import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1f54c64e",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['PYTHONHASHSEED'] = str(42)\n",
    "np.random.seed(42)\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4b9ad9c",
   "metadata": {},
   "source": [
    "<h1 style=\"background-color:LightGreen;\"> <center> <a id='start_cell'></a> Table Of Contents </center></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed273d49",
   "metadata": {},
   "source": [
    "[Create Datasets](#create_dataset) </br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a85c92a1",
   "metadata": {},
   "source": [
    "<h1 style=\"background-color:#3cA8EF;\"> <center> <a id='create_dataset'></a> Choose Files </center> </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "013559c1",
   "metadata": {},
   "source": [
    "<h1 style=\"color:red\"> Choose speakers with at least 10 files </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0756bd95",
   "metadata": {},
   "outputs": [],
   "source": [
    "if sys.platform != \"win32\":\n",
    "    # linux    \n",
    "    dataset_path = \"\"\n",
    "else:\n",
    "    # windows    \n",
    "    dataset_path = r\"C:\\Users\\amitli\\Datasets\\cv-corpus-14.0-2023-06-23\\ru\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2fd8bcb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "CHOOSE_FILES = False\n",
    "    \n",
    "if CHOOSE_FILES is True:   \n",
    "    train_df = pd.read_csv(dataset_path + \"/train.tsv\", delimiter=\"\\t\")\n",
    "    test_df  = pd.read_csv(dataset_path + \"/test.tsv\",  delimiter=\"\\t\")\n",
    "    df_all   = pd.concat([train_df, test_df])\n",
    "    \n",
    "    grouped         = df_all.groupby('client_id')\n",
    "    filtered_groups = grouped.filter(lambda x: len(x) >= 10)\n",
    "    df              = pd.DataFrame(filtered_groups)\n",
    "    \n",
    "    df.to_csv(\"cv_14_walkie_ru.csv\")\n",
    "else:\n",
    "    df = pd.read_csv(\"cv_14_walkie_ru.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1ff53b88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of speakers: 527\n",
      "Dataframe size    : 29415\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of speakers: {len(set(df.client_id.values))}\")\n",
    "print(f\"Dataframe size    : {len(df)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23956159",
   "metadata": {},
   "source": [
    "<h1 style=\"background-color:#3cA8EF;\"> <center> <a id='player'></a> Player </center> </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6d2b3893",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.4.0 (SDL 2.26.4, Python 3.10.0)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "from pygame import mixer\n",
    "import time\n",
    "import IPython\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d985a44a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def play_file(filename, fileLengthInSeconds):\n",
    "    mixer.music.load(filename)\n",
    "    mixer.music.play()\n",
    "    time.sleep(fileLengthInSeconds)\n",
    "    time.sleep(0.1)\n",
    "    while mixer.music.get_busy():  \n",
    "        print(\"\\n---> busy - wait -----\\n\")\n",
    "        time.sleep(1)\n",
    "    time.sleep(0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "cdc3ef5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def play_language(df, dataset_path,  start_from_client=0):\n",
    "        \n",
    "    current_date = datetime.datetime.now().strftime('%d_%m_%Y_%H_%M_%S')        \n",
    "    all_clients  = list(set(df.client_id.values))\n",
    "\n",
    "    mixer.init()     \n",
    "    start_time = time.time()\n",
    "    with open(f\"log_{current_date}.txt\", \"w\") as f:\n",
    "        for c_i in range(len(all_clients)):  \n",
    "            \n",
    "            if c_i < start_from_client:\n",
    "                continue\n",
    "            \n",
    "            client_id    = all_clients[c_i]\n",
    "            df_client    = df[df.client_id == client_id]            \n",
    "            client_files = df_client.path.values\n",
    "                                                            \n",
    "            str_log   = f\"\\n\\nClient_Id: {client_id} [{c_i+1}/{len(all_clients)}] Files: {len(client_files)}\"        \n",
    "            print(str_log)\n",
    "            f.write(str_log)\n",
    "                          \n",
    "            for file_i in range(len(client_files)):      \n",
    "                \n",
    "                file         = client_files[file_i]\n",
    "                fullFilePath = f\"{dataset_path}/clips/{file}\"\n",
    "                fileLength   = AudioSegment.from_mp3(fullFilePath).duration_seconds\n",
    "                           \n",
    "                end_time = time.time()\n",
    "                str_log = f\"\\n\\t[{file_i+1}/{len(client_files)}] Start Play file: {file}, Elapse: {round(end_time-start_time, 3)}\"\n",
    "                print(str_log)\n",
    "                f.write(str_log)\n",
    "                \n",
    "                #play_file(fullFilePath, fileLength)\n",
    "                end_start = time.time()\n",
    "\n",
    "                str_log = f\"\\n\\t[{file_i+1}/{len(client_files)}] ---> Played file: {file}, length: {fileLength} seconds, Elapse: {round(end_start-start_time, 3)}\"\n",
    "                print(str_log)\n",
    "                f.write(str_log)\n",
    "                time.sleep(0.2)  \n",
    "                  \n",
    "            time.sleep(0.2)  \n",
    "            \n",
    "        end_time = time.time()        \n",
    "        str_log = f\"\\nClose File, Elapse: {round(end_time-start_time, 3)}\"\n",
    "        print(str_log)\n",
    "        f.write(str_log)\n",
    "\n",
    "        f.close()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b676a3b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "play_language(df, dataset_path, start_from_client=0)        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3786c58",
   "metadata": {},
   "source": [
    "<h1 style=\"background-color:#3cA8EF;\"> <center><a id='parseLog'></a> Parse player log </center> </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "8b721e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_log(log_file):\n",
    "    \n",
    "    arr_clients            = []   # arr of client_id [may be duplicate - depends on num of files per client]\n",
    "    arr_cv                 = []   # cv file\n",
    "    arr_time               = []   # cv file length    \n",
    "    arr_num_cv_per_speaker = []   # for each speaker - number of speechs\n",
    "    arr_start_speech_time  = []   # for each speech - start time\n",
    "    arr_end_speech_time    = []\n",
    "\n",
    "    with open(log_file) as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "        counter     = 0\n",
    "        last_client = None\n",
    "        start_time  = None        \n",
    "        \n",
    "        for line in lines:\n",
    "\n",
    "            if line.find(\"Client_Id\") != -1:\n",
    "                \n",
    "                client      = line[line.find(\": \")+2 : line.find(\" [\")]\n",
    "                last_client = client\n",
    "                if counter > 0:\n",
    "                    arr_num_cv_per_speaker.append(counter) \n",
    "                    counter = 0\n",
    "                    \n",
    "                 \n",
    "            elif line.find(\"Start Play file:\") != -1:                     \n",
    "                start_time = float(line[line.find(\"Elapse:\")+8:])                \n",
    "\n",
    "                    \n",
    "            elif line.find(\"---> Played file\") != -1:                \n",
    "                cv_file = line[line.find(\": c\")+2 : line.find(\", \")]\n",
    "                length  = float(line[line.find(\"length:\")+8 : line.find(\" seconds\")])                \n",
    "                end_t   = float(line[line.find(\"Elapse: \")+8:])                \n",
    "                counter = counter + 1\n",
    "                \n",
    "                arr_clients.append(last_client)\n",
    "                arr_cv.append(cv_file)\n",
    "                arr_time.append(length)                \n",
    "                arr_end_speech_time.append(end_t)\n",
    "                if start_time is not None:\n",
    "                    arr_start_speech_time.append(start_time)\n",
    "                    start_time = None\n",
    "                else:\n",
    "                    print(f\"Error, start_time is None\")\n",
    "           \n",
    "            \n",
    "    arr_num_cv_per_speaker.append(counter)         \n",
    "    print(f\"Total number of speakers: {len(set(arr_clients))}, files: {len(set(arr_cv))}, langs: {len(set(arr_lang))}\")\n",
    "    print(f\"len(arr_start_speech_time) = {len(arr_start_speech_time)}\")\n",
    "    return arr_clients, arr_cv, arr_time,  arr_num_cv_per_speaker, arr_start_speech_time, arr_end_speech_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "702da06d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of speakers: 2, files: 130, langs: 5\n",
      "len(arr_start_speech_time) = 130\n"
     ]
    }
   ],
   "source": [
    "NIGHT_RUN_1 = r\"C:\\Users\\amitli\\Repo\\WalkieTalkieRecorder\\log_01_04_2024_15_03_43.txt\"\n",
    "arr_clients, arr_cv, arr_time,  arr_num_cv_per_speaker, arr_start_speech_time, arr_end_speech_time = parse_log(NIGHT_RUN_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "425c9635",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "968af89d",
   "metadata": {},
   "source": [
    "<h1 style=\"background-color:#3cA8EF;\"> <center> <a id='Reciever'></a> Reciever </center> </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "2f63994c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses        import dataclass, asdict\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from pydub              import AudioSegment,silence\n",
    "\n",
    "import datetime\n",
    "import pyaudio\n",
    "import wave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39aace47",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "@dataclass\n",
    "class StreamParams:\n",
    "    format: int            = pyaudio.paInt16\n",
    "    channels: int          = 1\n",
    "    rate: int              = 8000\n",
    "    frames_per_buffer: int = 1024\n",
    "    input: bool            = True\n",
    "    output: bool           = False\n",
    "\n",
    "    def to_dict(self) -> dict:\n",
    "        return asdict(self)\n",
    "\n",
    "class Recorder:\n",
    "    \"\"\"Recorder uses the blocking I/O facility from pyaudio to record sound\n",
    "    from mic.\n",
    "    Attributes:\n",
    "        - stream_params: StreamParams object with values for pyaudio Stream\n",
    "            object\n",
    "    \"\"\"\n",
    "    def __init__(self, stream_params: StreamParams) -> None:\n",
    "        self.stream_params = stream_params\n",
    "        self._pyaudio      = None\n",
    "        self._stream       = None\n",
    "        self._wav_file     = None\n",
    "        self._counter      = 0\n",
    "\n",
    "    def record(self, duration: int, save_path: str, num_files_to_create: int) -> None:\n",
    "        \"\"\"Record sound from mic for a given amount of seconds.\n",
    "        :param duration: Number of seconds we want to record for\n",
    "        :param save_path: Where to store recording\n",
    "        \"\"\"\n",
    "        print(\"Start recording...\")\n",
    "        self.save_path = save_path\n",
    "        self._create_recording_resources()\n",
    "        self._write_wav_file_reading_from_stream(save_path, duration, num_files_to_create)\n",
    "        self._close_recording_resources()\n",
    "        print(\"Stop recording\")\n",
    "\n",
    "    def create_current_wav_file(self):\n",
    "        \n",
    "        self._counter = self._counter + 1 \n",
    "        the_time  = datetime.datetime.now().strftime(\"%d_%m_%Y_%H_%M_%S%z\")\n",
    "        ctr_str   = f'{self._counter:04}'\n",
    "        save_path = self.save_path.replace(\".wav\",f\"_C_{ctr_str}_D_{the_time}.wav\")        \n",
    "        self._create_wav_file(save_path)\n",
    "    \n",
    "    def _create_recording_resources(self) -> None:\n",
    "        self._pyaudio = pyaudio.PyAudio()\n",
    "        self._stream = self._pyaudio.open(**self.stream_params.to_dict())\n",
    "        self.create_current_wav_file()\n",
    "\n",
    "    def _create_wav_file(self, save_path: str):\n",
    "        print(f\"creating new wav: {save_path}\")\n",
    "        self._wav_file = wave.open(save_path, \"wb\")\n",
    "        self._wav_file.setnchannels(self.stream_params.channels)\n",
    "        self._wav_file.setsampwidth(self._pyaudio.get_sample_size(self.stream_params.format))\n",
    "        self._wav_file.setframerate(self.stream_params.rate)\n",
    "\n",
    "\n",
    "    def close_current_wav_file(self, wav_file) -> None:\n",
    "        wav_file.close()\n",
    "\n",
    "    def _write_wav_file_reading_from_stream(self, save_path: str, duration: int, num_files_to_create: int) -> None:\n",
    "        with ThreadPoolExecutor(max_workers = 5) as executor:\n",
    "            for i in range(num_files_to_create):\n",
    "                for _ in range(int(self.stream_params.rate * duration / self.stream_params.frames_per_buffer)):\n",
    "                    audio_data = self._stream.read(self.stream_params.frames_per_buffer)\n",
    "                    self._wav_file.writeframes(audio_data)\n",
    "                    \n",
    "                executor.submit(self.close_current_wav_file, self._wav_file)\n",
    "                if i < num_files_to_create-1:\n",
    "                    self.create_current_wav_file()\n",
    "\n",
    "    def _close_recording_resources(self) -> None:\n",
    "        self._stream.close()\n",
    "        self._pyaudio.terminate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb0a67b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d740d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "stream_params      = StreamParams()\n",
    "stream_params.rate = 16000\n",
    "recorder           = Recorder(stream_params)\n",
    "recorder.record(60, \"/home/amitli/Datasets/speakathon/audio.wav\", num_files_to_create=60*18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1c7098a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a97db72f",
   "metadata": {},
   "source": [
    "<h1 style=\"background-color:#3cA8EF;\"> <center><a id='ParseRecords'></a>  Parse recordings </center> </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a0282eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sorted_files(files_path):\n",
    "    all_files = glob.glob(files_path)\n",
    "    all_files.sort()    \n",
    "    return all_files    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e124c394",
   "metadata": {},
   "outputs": [],
   "source": [
    "NIGHT_RUN_INPUT_FOLDER = r\"/home/amitli/Debug/25_26_jul/Night_25_26/*\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "734e7cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_files = get_sorted_files(NIGHT_RUN_INPUT_FOLDER)\n",
    "one_file  = AudioSegment.from_wav(all_files[0]) \n",
    "for i in range(1, len(all_files)):\n",
    "    one_file = one_file + AudioSegment.from_wav(all_files[i])   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b3e6b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "NIGHT_RUN_1_ONE_FILE = r\"/home/amitli/Debug/25_26_jul/One_file/One_file.wav\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d3b2263",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_file.export(NIGHT_RUN_1_ONE_FILE, format=\"wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f71f8695",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_start_speech_time[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2539e0e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#AudioSegment.from_wav(r\"/home/amitli/Debug/25_26_jul/Night_25_26/audio_C_0001_D_25_07_2023_15_18_31.wav\")[9.9*1000:11*1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32455dc7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c66d098b",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_wav              = AudioSegment.from_wav(NIGHT_RUN_1_ONE_FILE)\n",
    "mp3_len               = arr_time\n",
    "num_of_speakers       = len(set(arr_clients))\n",
    "num_of_mp3_per_speker = arr_num_cv_per_speaker\n",
    "\n",
    "\n",
    "start_rec_time_ms = int(9.9*1000) - arr_start_speech_time[0] * 1000\n",
    "arr_results       = []\n",
    "counter           = 0\n",
    "end               = 0\n",
    "\n",
    "for i_speaker in range(num_of_speakers):\n",
    "   \n",
    "    for i_mp3 in range(num_of_mp3_per_speker[i_speaker]):\n",
    "                \n",
    "        # --- speech\n",
    "        start = start_rec_time_ms + arr_start_speech_time[counter]*1000\n",
    "        #end   = arr_end_speech_time[counter]*1000 + start_rec_time_ms\n",
    "        end   = start + mp3_len[counter]*1000   \n",
    "        \n",
    "        \n",
    "        if end > len(full_wav):\n",
    "            break\n",
    "                   \n",
    "        arr_results.append(full_wav[start-300 : end])                   \n",
    "        counter = counter + 1\n",
    "           \n",
    "\n",
    "print(f\"Finished at = {end} / {len(full_wav)}, Found: {len(arr_results)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a2f4fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = 2354\n",
    "arr_results[test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7f94878",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eae4751b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{arr_cv[test]}, {arr_time[test]}, recorded: {arr_results[test].duration_seconds}\")\n",
    "AudioSegment.from_mp3(f\"{ARABIC_PATH}/clips/{arr_cv[test]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10861ba7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f6edad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "last_speaker  = 0\n",
    "export_path   = \"/home/amitli/Debug/25_26_jul/Outputs_wav\"\n",
    "full_path     = \"\"\n",
    "for i in tqdm(range(2993)):\n",
    "    \n",
    "    speaker     = arr_clients[i]\n",
    "    if speaker != last_speaker:\n",
    "        expoer_folder = speaker\n",
    "        full_path     = f\"{export_path}/{speaker}\"\n",
    "        if not os.path.exists(full_path):  \n",
    "            os.makedirs(full_path)        \n",
    "        \n",
    "    last_speaker = speaker\n",
    "    tactic_file  = arr_results[i]\n",
    "    cv_name      = arr_cv[i]\n",
    "    lang         = arr_lang[i]\n",
    "    \n",
    "    file_name    = f\"tactic_{lang}_{cv_name}\"\n",
    "    #arr_results[i].export(f\"{full_path}/{file_name}\", format=\"mp3\")\n",
    "    arr_results[i].export(f\"{full_path}/{file_name[:-4]}.wav\", format=\"wav\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b27cf8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "28c81e2c",
   "metadata": {},
   "source": [
    "<h1 style=\"background-color:#3cA8EF;\"> <center> <a id='Plot_dBFS'></a>  Plot (dBFS) </center> </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "604bd745",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "import numpy as np\n",
    "import wave\n",
    "\n",
    "def read_wav_file(file_path):\n",
    "    with wave.open(file_path, \"rb\") as wav_file:\n",
    "        num_frames   = wav_file.getnframes()\n",
    "        sample_width = wav_file.getsampwidth()\n",
    "        sample_rate  = wav_file.getframerate()\n",
    "        audio_data   = np.frombuffer(wav_file.readframes(num_frames), dtype=np.int16) \n",
    "    return audio_data, sample_rate\n",
    "\n",
    "\n",
    "def convert_to_dbfs(audio_data):\n",
    "    max_value = np.max(np.abs(audio_data))\n",
    "    dbfs = 20 * np.log10(audio_data.astype(np.float32) / max_value)\n",
    "    return dbfs\n",
    "\n",
    "\n",
    "def plot_dBFS(audio_data, sample_rate):\n",
    "    duration = len(audio_data) / sample_rate\n",
    "    time = np.linspace(0, duration, len(audio_data))\n",
    "    dbfs = convert_to_dbfs(audio_data)\n",
    "\n",
    "    fig = go.Figure()\n",
    "    fig.add_trace(go.Scatter(x=time, y=dbfs, mode=\"lines\"))\n",
    "    fig.update_layout(\n",
    "        title=\"dBFS Plot\",\n",
    "        xaxis_title=\"Time (s)\",\n",
    "        yaxis_title=\"dBFS\",\n",
    "    )\n",
    "    return fig\n",
    "\n",
    "    \n",
    "file_path = r\"/home/amitli/Debug/25_26_jul/Night_25_26/audio_C_0001_D_25_07_2023_15_18_31.wav\"\n",
    "audio_data, sample_rate = read_wav_file(file_path)\n",
    "fig                     = plot_dBFS(audio_data, sample_rate)\n",
    "fig.show()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a972a7a6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
